{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4002f40-a2ca-4253-a45c-91078f38163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "#!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
    "#!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "#!pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328597d1-1376-4ded-a8c3-8409b2803440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastVisionModel # FastLanguageModel for LLMs\n",
    "import torch\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624addd",
   "metadata": {},
   "source": [
    "## Qwen2.5 7b finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b71aca62-9f24-4f76-ad95-eecd1cd5a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/data/models/qwen2_5_ 7b_outputs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4028e221-e670-455f-8077-114dd2b5b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_dir = Path(\"/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb9e5b0-7b5e-41c4-8bb5-51e7efe1a7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Qwen2_5_VLForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d25c1274-5e2a-42b1-b7c4-5eece82c8c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Qwen2 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA RTX A5000. Num GPUs = 1. Max memory: 23.679 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    model_path,\n",
    "    load_in_4bit=True,\n",
    "    #use_gradient_checkpointing=\"unsloth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "add261fe-9969-48a9-b8de-ba5e27dba4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccbf7a4-2b73-4f7a-94cc-88b25061a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from unsloth import FastVisionModel\n",
    "from PIL import Image\n",
    "\n",
    "class QwenProcessor:\n",
    "    def __init__(self):\n",
    "        self.base_data_dir = Path(\"/data\")\n",
    "        self.model_mapper = {\n",
    "            \"Qwen2_5-3b_finetuned\": str(self.base_data_dir / \"models/qwen2_5_3b_outputs\"),\n",
    "            \"Qwen2_5-7b_finetuned\": str(self.base_data_dir / \"models/qwen2_5_ 7b_outputs\"),\n",
    "            \"Qwen2-vl-7b_finetuned\": str(self.base_data_dir / \"models/qwen2_VL_7b/lora_model\"),\n",
    "            \"Qwen2_5-3b\": \"unsloth/Qwen2.5-VL-3B-Instruct\",\n",
    "            \"Qwen2_5-7b\": \"unsloth/Qwen2.5-VL-7B-Instruct\",\n",
    "            \"Qwen2-vl-7b\": \"unsloth/Qwen2-VL-7B-Instruct\"   \n",
    "        }\n",
    "        self.loaded_models = {}\n",
    "\n",
    "    def get_available_models(self):\n",
    "        return self.model_mapper.keys()\n",
    "\n",
    "    def clear_cache(self):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    def unload_model(self, model):\n",
    "        del model\n",
    "        self.clear_cache()\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ‚Äî –≤–µ—Ä–Ω—É—Ç—å –µ—ë\n",
    "        if model_name in self.loaded_models:\n",
    "            return self.loaded_models[model_name]\n",
    "\n",
    "        # –í—ã–≥—Ä—É–∑–∏—Ç—å –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        for name, (model, _) in self.loaded_models.items():\n",
    "            if name != model_name:\n",
    "                self.unload_model(model)\n",
    "        self.loaded_models.clear()\n",
    "\n",
    "        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å\n",
    "        model, tokenizer = FastVisionModel.from_pretrained(\n",
    "            self.model_mapper[model_name],\n",
    "            load_in_4bit=True,\n",
    "            #use_gradient_checkpointing=\"unsloth\",\n",
    "        )\n",
    "        FastVisionModel.for_inference(model)\n",
    "        self.loaded_models[model_name] = (model, tokenizer)\n",
    "        return model, tokenizer\n",
    "\n",
    "    def process(self, system_prompt, user_prompt, image: Image, selected_model, temperature=0.2):\n",
    "        model, tokenizer = self.load_model(selected_model)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": user_prompt}\n",
    "            ]}\n",
    "        ]\n",
    "        input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            [image],  # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —ç—Ç–æ —Å–ø–∏—Å–æ–∫\n",
    "            [input_text],\n",
    "            add_special_tokens=False,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        input_ids = inputs[\"input_ids\"][0]\n",
    "\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            use_cache=True,\n",
    "            temperature=temperature,\n",
    "            min_p=0.1,\n",
    "        )[0]\n",
    "\n",
    "        # –£–¥–∞–ª—è–µ–º prompt, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ\n",
    "        generated_only_ids = output_ids[len(input_ids):]\n",
    "\n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –≤ —Ç–µ–∫—Å—Ç\n",
    "        recognized_text = tokenizer.decode(generated_only_ids, skip_special_tokens=True)\n",
    "\n",
    "        return f\"{recognized_text}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f251bd-f77c-436d-be71-95a73f77d22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=229x69>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sample_image = Image.open(base_data_dir / \"names/44.jpg\")\n",
    "sample_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23840d68-4b0b-44d0-87e2-159ecb61bf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1419b1ac-55c2-4bdc-b981-3482c6a6a9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 12 15:29:09 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.216.03             Driver Version: 535.216.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000               Off | 00000000:00:06.0 Off |                  Off |\n",
      "| 30%   30C    P8               6W / 230W |    412MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48fbcab5-e669-4771-aac5-d6d1c2802bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Qwen2 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA RTX A5000. Num GPUs = 1. Max memory: 23.679 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PeftModelForCausalLM(\n",
       "   (base_model): LoraModel(\n",
       "     (model): Qwen2_5_VLForConditionalGeneration(\n",
       "       (visual): Qwen2_5_VisionTransformerPretrainedModel(\n",
       "         (patch_embed): Qwen2_5_VisionPatchEmbed(\n",
       "           (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
       "         )\n",
       "         (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()\n",
       "         (blocks): ModuleList(\n",
       "           (0-25): 26 x Qwen2_5_VLVisionBlock(\n",
       "             (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "             (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "             (attn): Qwen2_5_VLVisionSdpaAttention(\n",
       "               (qkv): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3840, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "             )\n",
       "             (mlp): Qwen2_5_VLMLP(\n",
       "               (gate_proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3420, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (up_proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3420, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (down_proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=3420, out_features=1280, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=3420, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (act_fn): SiLU()\n",
       "             )\n",
       "           )\n",
       "           (26): Qwen2_5_VLVisionBlock(\n",
       "             (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "             (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "             (attn): Qwen2_5_VLVisionSdpaAttention(\n",
       "               (qkv): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=1280, out_features=3840, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3840, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "             )\n",
       "             (mlp): Qwen2_5_VLMLP(\n",
       "               (gate_proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3420, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (up_proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3420, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (down_proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=3420, out_features=1280, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=3420, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (act_fn): SiLU()\n",
       "             )\n",
       "           )\n",
       "           (27-29): 3 x Qwen2_5_VLVisionBlock(\n",
       "             (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "             (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "             (attn): Qwen2_5_VLVisionSdpaAttention(\n",
       "               (qkv): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3840, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "             )\n",
       "             (mlp): Qwen2_5_VLMLP(\n",
       "               (gate_proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3420, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (up_proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3420, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (down_proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=3420, out_features=1280, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=3420, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (act_fn): SiLU()\n",
       "             )\n",
       "           )\n",
       "           (30): Qwen2_5_VLVisionBlock(\n",
       "             (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "             (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "             (attn): Qwen2_5_VLVisionSdpaAttention(\n",
       "               (qkv): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3840, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "             )\n",
       "             (mlp): Qwen2_5_VLMLP(\n",
       "               (gate_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=1280, out_features=3420, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3420, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (up_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=1280, out_features=3420, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3420, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (down_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=3420, out_features=1280, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=3420, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (act_fn): SiLU()\n",
       "             )\n",
       "           )\n",
       "           (31): Qwen2_5_VLVisionBlock(\n",
       "             (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "             (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "             (attn): Qwen2_5_VLVisionSdpaAttention(\n",
       "               (qkv): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3840, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "             )\n",
       "             (mlp): Qwen2_5_VLMLP(\n",
       "               (gate_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=1280, out_features=3420, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3420, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (up_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=1280, out_features=3420, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=1280, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3420, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (down_proj): lora.Linear(\n",
       "                 (base_layer): Linear(in_features=3420, out_features=1280, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=3420, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=1280, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (act_fn): SiLU()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (merger): Qwen2_5_VLPatchMerger(\n",
       "           (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "           (mlp): Sequential(\n",
       "             (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "             (1): GELU(approximate='none')\n",
       "             (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (model): Qwen2_5_VLModel(\n",
       "         (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n",
       "         (layers): ModuleList(\n",
       "           (0-27): 28 x Qwen2_5_VLDecoderLayer(\n",
       "             (self_attn): Qwen2_5_VLSdpaAttention(\n",
       "               (q_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (k_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (v_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (o_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
       "             )\n",
       "             (mlp): Qwen2MLP(\n",
       "               (gate_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (up_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=18944, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (down_proj): lora.Linear4bit(\n",
       "                 (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
       "                 (lora_dropout): ModuleDict(\n",
       "                   (default): Identity()\n",
       "                 )\n",
       "                 (lora_A): ModuleDict(\n",
       "                   (default): Linear(in_features=18944, out_features=16, bias=False)\n",
       "                 )\n",
       "                 (lora_B): ModuleDict(\n",
       "                   (default): Linear(in_features=16, out_features=3584, bias=False)\n",
       "                 )\n",
       "                 (lora_embedding_A): ParameterDict()\n",
       "                 (lora_embedding_B): ParameterDict()\n",
       "                 (lora_magnitude_vector): ModuleDict()\n",
       "               )\n",
       "               (act_fn): SiLU()\n",
       "             )\n",
       "             (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "             (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "           )\n",
       "         )\n",
       "         (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "         (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
       "       )\n",
       "       (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Qwen2_5_VLProcessor:\n",
       " - image_processor: Qwen2VLImageProcessor {\n",
       "   \"do_convert_rgb\": true,\n",
       "   \"do_normalize\": true,\n",
       "   \"do_rescale\": true,\n",
       "   \"do_resize\": true,\n",
       "   \"image_mean\": [\n",
       "     0.48145466,\n",
       "     0.4578275,\n",
       "     0.40821073\n",
       "   ],\n",
       "   \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
       "   \"image_std\": [\n",
       "     0.26862954,\n",
       "     0.26130258,\n",
       "     0.27577711\n",
       "   ],\n",
       "   \"max_pixels\": 12845056,\n",
       "   \"merge_size\": 2,\n",
       "   \"min_pixels\": 3136,\n",
       "   \"patch_size\": 14,\n",
       "   \"processor_class\": \"Qwen2_5_VLProcessor\",\n",
       "   \"resample\": 3,\n",
       "   \"rescale_factor\": 0.00392156862745098,\n",
       "   \"size\": {\n",
       "     \"longest_edge\": 12845056,\n",
       "     \"shortest_edge\": 3136\n",
       "   },\n",
       "   \"temporal_patch_size\": 2\n",
       " }\n",
       " \n",
       " - tokenizer: Qwen2TokenizerFast(name_or_path='/data/models/qwen2_5_ 7b_outputs', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|vision_pad|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       " \t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " \t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " }\n",
       " )\n",
       " \n",
       " {\n",
       "   \"processor_class\": \"Qwen2_5_VLProcessor\"\n",
       " })"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen_processor = QwenProcessor()\n",
    "qwen_processor.clear_cache()\n",
    "qwen_processor.load_model(\"Qwen2_5-7b_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9d0e8556-75b6-454e-a982-9fe2c8612016",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT  = '''\n",
    "–í—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç OCR , –∫–æ—Ç–æ—Ä—ã–π –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Ä—É—Å—Å–∫–∏—Ö —Ç–æ–≤–∞—Ä–Ω—ã—Ö —ç—Ç–∏–∫–µ—Ç–æ–∫ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö. –í —Ç–µ–∫—Å—Ç–µ –º–æ–≥—É—Ç –≤—Å—Ç—Ä–µ—á–∞—Ç—å—Å—è –Ω–∞–∑–≤–∞–Ω–∏—è –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º.\n",
    "\n",
    "'''\n",
    "\n",
    "USER_PROMPT = '''\n",
    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏–∑–≤–ª–µ–∫–∏—Ç–µ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏ –Ω–∏—á–µ–≥–æ –±–æ–ª—å—à–µ –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤. \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7cbd4cae-29ea-43f6-8d5e-9b24a64b31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "151db5c5-ff0d-4ab4-996b-a95c8d8dfdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Qwen2 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA RTX A5000. Num GPUs = 1. Max memory: 23.679 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m result_text \u001b[38;5;241m=\u001b[39m \u001b[43mqwen_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSYSTEM_PROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUSER_PROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQwen2_5-7b_finetuned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(end_time \u001b[38;5;241m-\u001b[39m start_time)\n",
      "Cell \u001b[0;32mIn[92], line 53\u001b[0m, in \u001b[0;36mQwenProcessor.process\u001b[0;34m(self, system_prompt, user_prompt, image, selected_model, temperature)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, system_prompt, user_prompt, image: Image, selected_model, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m):\n\u001b[0;32m---> 53\u001b[0m     model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt},\n\u001b[1;32m     56\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m         ]}\n\u001b[1;32m     60\u001b[0m     ]\n\u001b[1;32m     61\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[92], line 43\u001b[0m, in \u001b[0;36mQwenProcessor.load_model\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_models\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mFastVisionModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_mapper\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#use_gradient_checkpointing=\"unsloth\",\u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m FastVisionModel\u001b[38;5;241m.\u001b[39mfor_inference(model)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_models[model_name] \u001b[38;5;241m=\u001b[39m (model, tokenizer)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/loader.py:732\u001b[0m, in \u001b[0;36mFastModel.from_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, return_logits, fullgraph, use_exact_model_name, auto_model, whisper_language, whisper_task, *args, **kwargs)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     auto_model \u001b[38;5;241m=\u001b[39m AutoModelForVision2Seq \u001b[38;5;28;01mif\u001b[39;00m is_vlm \u001b[38;5;28;01melse\u001b[39;00m AutoModelForCausalLM\n\u001b[0;32m--> 732\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mFastBaseModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_finetuning\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfull_finetuning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_peft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_types\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_gradient_checkpointing\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_gradient_checkpointing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43msupports_sdpa\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msupports_sdpa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhisper_language\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwhisper_language\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhisper_task\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwhisper_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resize_model_vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    754\u001b[0m     model\u001b[38;5;241m.\u001b[39mresize_token_embeddings(resize_model_vocab)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/vision.py:359\u001b[0m, in \u001b[0;36mFastBaseModel.from_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, full_finetuning, token, device_map, trust_remote_code, model_types, tokenizer_name, auto_model, use_gradient_checkpointing, supports_sdpa, whisper_language, whisper_task, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m torch_dtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_forced_float32: torch_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16\n\u001b[0;32m--> 359\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mauto_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# quantization_config   = bnb_config,\u001b[39;49;00m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# attn_implementation   = attn_implementation,\u001b[39;49;00m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Return old flag\u001b[39;00m\n\u001b[1;32m    370\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHF_HUB_ENABLE_HF_TRANSFER\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m old_hf_transfer\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:571\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    570\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:279\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4380\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4378\u001b[0m \u001b[38;5;66;03m# Prepare the full device map\u001b[39;00m\n\u001b[1;32m   4379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4380\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m \u001b[43m_get_device_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4382\u001b[0m \u001b[38;5;66;03m# Finalize model weight initialization\u001b[39;00m\n\u001b[1;32m   4383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_tf:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1304\u001b[0m, in \u001b[0;36m_get_device_map\u001b[0;34m(model, device_map, max_memory, hf_quantizer, torch_dtype, keep_in_fp32_regex)\u001b[0m\n\u001b[1;32m   1301\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m infer_auto_device_map(model, dtype\u001b[38;5;241m=\u001b[39mtarget_dtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdevice_map_kwargs)\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1304\u001b[0m         \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     tied_params \u001b[38;5;241m=\u001b[39m find_tied_parameters(model)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py:104\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.validate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 104\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`from_pretrained`. Check \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(importlib\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitsandbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m<\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.39.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have a version of `bitsandbytes` that is not compatible with 4bit inference and training\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you have the latest version of `bitsandbytes` installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "result_text = qwen_processor.process(SYSTEM_PROMPT, USER_PROMPT, sample_image, \"Qwen2_5-7b_finetuned\", temperature=0.2)\n",
    "end_time = time.time()\n",
    "\n",
    "print(end_time - start_time)\n",
    "print(result_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
