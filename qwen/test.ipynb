{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4002f40-a2ca-4253-a45c-91078f38163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "#!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
    "#!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "#!pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328597d1-1376-4ded-a8c3-8409b2803440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastVisionModel # FastLanguageModel for LLMs\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817f3627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aca81e-e7a4-478b-bf5c-4c5b68d69f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.save_pretrained(\"models/qwe2_5_3b_full\")\n",
    "#tokenizer.save_pretrained(\"models/qwe2_5_3b_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4564bb-c4b5-45a9-973f-66a1ac0a2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoTokenizer\n",
    "#\n",
    "## –£–∫–∞–∑—ã–≤–∞–µ–º –ø—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä—É\n",
    "#model_path = \"models/qwe2_5_3b_full\"\n",
    "#\n",
    "## –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä\n",
    "#model = FastVisionModel.from_pretrained(model_path, load_in_4bit=True, use_gradient_checkpointing=\"unsloth\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2d8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-06 06:37:28--  https://docs.google.com/spreadsheets/d/1riSLCvdlQ8kC5DshtqlRAsVEa7R7N2kD/export?format=xlsx\n",
      "Resolving docs.google.com (docs.google.com)... 74.125.205.194, 2a00:1450:4010:c02::c2\n",
      "Connecting to docs.google.com (docs.google.com)|74.125.205.194|:443... connected.\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307 Temporary Redirect\n",
      "Location: https://doc-0k-3k-sheets.googleusercontent.com/export/54bogvaave6cua4cdnls17ksc4/1a07496inq9bch4p8p9pj9da3c/1746513445000/113369956649761615778/*/1riSLCvdlQ8kC5DshtqlRAsVEa7R7N2kD?format=xlsx [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2025-05-06 06:37:28--  https://doc-0k-3k-sheets.googleusercontent.com/export/54bogvaave6cua4cdnls17ksc4/1a07496inq9bch4p8p9pj9da3c/1746513445000/113369956649761615778/*/1riSLCvdlQ8kC5DshtqlRAsVEa7R7N2kD?format=xlsx\n",
      "Resolving doc-0k-3k-sheets.googleusercontent.com (doc-0k-3k-sheets.googleusercontent.com)... 64.233.164.132, 2a00:1450:4010:c07::84\n",
      "Connecting to doc-0k-3k-sheets.googleusercontent.com (doc-0k-3k-sheets.googleusercontent.com)|64.233.164.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/vnd.openxmlformats-officedocument.spreadsheetml.sheet]\n",
      "Saving to: ‚Äò–ø—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–Ω–Ω–∏–∫–æ–≤.xls‚Äô\n",
      "\n",
      "–ø—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–Ω–Ω–∏–∫–æ–≤.x     [ <=>                ]  53.79K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2025-05-06 06:37:28 (1.37 MB/s) - ‚Äò–ø—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–Ω–Ω–∏–∫–æ–≤.xls‚Äô saved [55079]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget  -c \"https://docs.google.com/spreadsheets/d/1riSLCvdlQ8kC5DshtqlRAsVEa7R7N2kD/export?format=xlsx\" -O \"–ø—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–Ω–Ω–∏–∫–æ–≤.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b6544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "311c7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/data/–ø—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–Ω–Ω–∏–∫–æ–≤.xlsx\", header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a99c27e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>–ù–æ–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–∫–∏</th>\n",
       "      <th>–¶–µ–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è</th>\n",
       "      <th>–¶–µ–Ω–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç—å</th>\n",
       "      <th>–û—à–∏–±–∫–∞</th>\n",
       "      <th>–°—Ç—Ä–æ–∫–∞ 1</th>\n",
       "      <th>–°—Ç—Ä–æ–∫–∞ 2</th>\n",
       "      <th>–°—Ç—Ä–æ–∫–∞ 3</th>\n",
       "      <th>–°—Ç—Ä–æ–∫–∞ 4</th>\n",
       "      <th>–°—Ç—Ä–æ–∫–∞ 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>54.99</td>\n",
       "      <td>54.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>–í–æ–¥–∞ –°–í–Ø–¢–û–ô –ò–°–¢–û–ß–ù–ò–ö</td>\n",
       "      <td>1.0–ª</td>\n",
       "      <td>–ø—Ä–∏—Ä–æ–¥–Ω–∞—è –ø–∏—Ç—å–µ–≤–∞—è –Ω–µ–≥–∞–∑.–ü–≠–¢</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>59.99</td>\n",
       "      <td>59.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>–í–æ–¥–∞ –°–≤—è—Ç–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫</td>\n",
       "      <td>0,75–ª</td>\n",
       "      <td>–Ω–µ–≥–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–ø–æ—Ä—Ç</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>51.99</td>\n",
       "      <td>51.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>–í–æ–¥–∞ –®–ò–®–ö–ò–ù –õ–ï–°</td>\n",
       "      <td>–ø–∏—Ç—å–µ–≤–∞—è 1–ª</td>\n",
       "      <td>–Ω–µ–≥–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24.99</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>–í–æ–¥–∞ –ö–†–ê–°–ù–ê–Ø –¶–ï–ù–ê</td>\n",
       "      <td>1,5–ª</td>\n",
       "      <td>–Ω–µ–≥–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>61.99</td>\n",
       "      <td>61.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>–í–æ–¥–∞ –°–í–Ø–¢–û–ô –ò–°–¢–û–ß–ù–ò–ö</td>\n",
       "      <td>1,5–ª</td>\n",
       "      <td>–∫–ª—é—á–µ–≤–∞—è, –±–µ–∑ –≥–∞–∑–∞ –ø–ª/–±</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   –ù–æ–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–∫–∏  –¶–µ–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è  –¶–µ–Ω–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç—å  –û—à–∏–±–∫–∞  \\\n",
       "0               1            54.99           54.99     0.0   \n",
       "1               2            59.99           59.99     0.0   \n",
       "2               3            51.99           51.99     0.0   \n",
       "3               4            24.99           24.99     0.0   \n",
       "4               5            61.99           61.99     0.0   \n",
       "\n",
       "               –°—Ç—Ä–æ–∫–∞ 1     –°—Ç—Ä–æ–∫–∞ 2                      –°—Ç—Ä–æ–∫–∞ 3 –°—Ç—Ä–æ–∫–∞ 4  \\\n",
       "0  –í–æ–¥–∞ –°–í–Ø–¢–û–ô –ò–°–¢–û–ß–ù–ò–ö         1.0–ª  –ø—Ä–∏—Ä–æ–¥–Ω–∞—è –ø–∏—Ç—å–µ–≤–∞—è –Ω–µ–≥–∞–∑.–ü–≠–¢      NaN   \n",
       "1  –í–æ–¥–∞ –°–≤—è—Ç–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫        0,75–ª          –Ω–µ–≥–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–ø–æ—Ä—Ç      NaN   \n",
       "2       –í–æ–¥–∞ –®–ò–®–ö–ò–ù –õ–ï–°  –ø–∏—Ç—å–µ–≤–∞—è 1–ª                –Ω–µ–≥–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è      NaN   \n",
       "3     –í–æ–¥–∞ –ö–†–ê–°–ù–ê–Ø –¶–ï–ù–ê         1,5–ª                –Ω–µ–≥–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è      NaN   \n",
       "4  –í–æ–¥–∞ –°–í–Ø–¢–û–ô –ò–°–¢–û–ß–ù–ò–ö         1,5–ª       –∫–ª—é—á–µ–≤–∞—è, –±–µ–∑ –≥–∞–∑–∞ –ø–ª/–±      NaN   \n",
       "\n",
       "   –°—Ç—Ä–æ–∫–∞ 5  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96798b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_dir = Path(\"/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4dec16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_data_dir / \"train_dataset.json\") as f:\n",
    "    train_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c15ee89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_data_dir / \"test_dataset.json\") as f:\n",
    "    test_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "141620fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 {'image_path': 'names/930.jpg', 'text': '–ú–æ–ª–æ–∫–æ –ö–†–ê–°–ù–ê–Ø –¶–ï–ù–ê\\n800–º–ª\\n–º–∏—Ç.–ø–∞—Å—Ç.2,5%'}\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataset), test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333f4dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an OCR expert specialized in extracting data from supermarket price tags.\"\n",
    "user_prompt = \"Extract textual information from the image. Output only the text without any reasoning.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1a69f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataset(sample):\n",
    "\n",
    "   sample_image = Image.open(base_data_dir / sample[\"image_path\"])\n",
    "   return [\n",
    "      {\"role\": \"system\",\n",
    "          \"content\": system_message\n",
    "      },\n",
    "      { \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt\n",
    "                    },\n",
    "                    {\"type\": \"image\", \"image\": sample_image}\n",
    "        ]\n",
    "      },\n",
    "      { \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"text\",  \"text\": sample[\"text\"]} ]\n",
    "      },\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97563695",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_test_dataset = [convert_dataset(sample) for sample in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5353cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ocr(image_path, model, temperature = 1.5):\n",
    "    FastVisionModel.for_inference(model)  # Enable for inference!\n",
    "    time_start = time.time()\n",
    "    image = Image.open(base_data_dir / image_path)\n",
    "    if image.height < 28 or image.width < 28:\n",
    "      return \"!!!–û–®–ò–ë–ö–ê. –ò—Ö–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ–Ω—å—à–µ 28—Ç–æ—á–µ–∫\", 0\n",
    "      \n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "          \"content\": system_message\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": user_prompt}\n",
    "        ]}\n",
    "    ]\n",
    "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        [image],  # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —ç—Ç–æ —Å–ø–∏—Å–æ–∫\n",
    "        [input_text],\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"][0]\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        temperature=temperature,\n",
    "        min_p=0.1,\n",
    "    )[0]\n",
    "\n",
    "    # –£–¥–∞–ª—è–µ–º prompt, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ\n",
    "    generated_only_ids = output_ids[len(input_ids):]\n",
    "\n",
    "\n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –≤ —Ç–µ–∫—Å—Ç\n",
    "    recognized_text = tokenizer.decode(generated_only_ids, skip_special_tokens=True)\n",
    "\n",
    "    time_end = time.time()\n",
    "    return recognized_text, time_end - time_start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624addd",
   "metadata": {},
   "source": [
    "## Qwen2.5 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05cced94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Qwen2 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A2. Num GPUs = 1. Max memory: 15.617 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/data/models/qwen2_5_3b_outputs\"\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    model_path,\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e229a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(columns=[\"file_path\", \"original_txt\", \"recognized_txt\", \"eot\"])  \n",
    "for i, sample in enumerate(test_dataset):\n",
    "    original_txt = sample[\"text\"]\n",
    "    recognized_txt, eot = process_ocr(sample[\"image_path\"], model)\n",
    "    file_name = sample[\"image_path\"]\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É –≤ DataFrame\n",
    "    print(\"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç:\", original_txt)\n",
    "    print(\"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\", recognized_txt)\n",
    "    print(\"–ó–∞—Ç—Ä–∞—á–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è:\", eot)\n",
    "    df_result.loc[i] = [file_name, original_txt, recognized_txt, eot]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f38a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_excel(base_data_dir / \"qwen2.5_3b_finetuned.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
